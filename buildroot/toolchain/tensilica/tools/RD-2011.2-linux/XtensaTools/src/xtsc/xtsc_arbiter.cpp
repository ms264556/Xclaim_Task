// Copyright (c) 2005-2010 by Tensilica Inc.  ALL RIGHTS RESERVED.
// These coded instructions, statements, and computer programs are the
// copyrighted works and confidential proprietary information of Tensilica Inc.
// They may not be modified, copied, reproduced, distributed, or disclosed to
// third parties in any manner, medium, or form, in whole or in part, without
// the prior written consent of Tensilica Inc.


#include <xtsc/xtsc_arbiter.h>
#include <xtsc/xtsc_cohctrl.h>
#include <xtsc/xtsc_core.h>
#include <xtsc/xtsc_dma_engine.h>
#include <xtsc/xtsc_master.h>
#include <xtsc/xtsc_memory_trace.h>
#include <xtsc/xtsc_pin2tlm_memory_transactor.h>
#include <xtsc/xtsc_router.h>
#include <xtsc/xtsc_logging.h>
#include <algorithm>
#include <cassert>


/*
 *  Theory of Operation
 *  
 *  Incoming requests are received in the nb_request() method.  Typically nb_request()
 *  hands the request over to the do_request() method and there a copy is made of the
 *  request which is then added to the appropriate FIFO (base on port) in the
 *  m_request_deques array and m_arbiter_thread_event is notified.  When not operating as
 *  a PIF width converter (PWC), this event is handled by arbiter_thread and when
 *  operating as a PWC it is handled by arbiter_pwc_thread.
 *
 *  Incoming responses are received in the nb_respond() method.  Typically a copy is
 *  made of the response which is then added to m_response_fifo and the
 *  m_response_thread_event is notified.  When not operating as a PWC, this event is
 *  handled by response_thread and when operating as a PWC it is handled by
 *  response_pwc_thread.
 *
 *  When "immediate_timing" is true, the threads are not used ("immediate_timing" must
 *  be false when operating as a PWC)
 *
 *  PWC Operation
 *
 *  If a request is received on an upstream PIF which has the same width as the
 *  downstream PIF, then the request is passed downstream unchanged.  Otherwise, the
 *  convert_request() method is called to perform all required conversions, including
 *  combining multiple requests into a single request, converting a single request into
 *  multiple requests, and changing the request type (i.e from a block request to a
 *  non-block request or vice-versa) and various other fields of the request.
 *
 *  If a response is received from the downstream PIF which is targeted to an upstream
 *  PIF of the same width, then the response is passed upstream unchanged.  Otherwise,
 *  the convert_response() method is called to perform all required conversions,
 *  including combining multiple responses into a single response and converting a
 *  single response into multiple responses.
 *
 *  When a response comes in on the downstream PIF interface that is targeted to a
 *  upstream PIF of a different width, then the response has to be match up to the
 *  original request so that the necessary conversions can be made to the response.  The
 *  arbiter uses the request and response ID fields to enable this match-up and so has
 *  to reassign the request ID in requests sent downstream to ensure uniqueness (of
 *  course, the original request ID has to be used for the responses sent back
 *  upstream).
 *
 *  The main structures associated with PWC operation are:
 *
 *  1) class req_rsp_info: This class holds the state information necessary for the
 *     entire sequence from the receipt of the request (or the first transfer of a
 *     BLOCK_WRITE or RCW request) until the response (or last response if BLOCK_READ)
 *     is sent back upstream.  
 *
 *  2) m_req_rsp_table[]: This array holds all outstanding req_rsp_info objects.  It is
 *     indexed by the downstream request ID.  The downstream request ID is assigned by
 *     the get_empty_slot() method which is called for all first requests handled by the
 *     convert_request() method.
 *
 *  3) m_requests[]: This array holds all ready-to-send-downstream requests generated by
 *     the call from arbiter_pwc_thread() to convert_request().  The array is empty when
 *     convert_request() is called and may or may not be empty when convert_request()
 *     returns.  If it is not empty, the arbiter_pwc_thread() sends each of the requests
 *     in it downstream before clearing it and calling convert_request() again for the
 *     next incoming request.  If the array is empty, then m_p_nascent_request in
 *     req_rsp_info will point to the partially formed converted request.
 *
 *  4) m_responses[]: This array holds all ready-to-send-upstream responses generated by
 *     the call from response_pwc_thread() to convert_response().  The array is
 *     empty when convert_response() is called and may or may not be empty when
 *     convert_response() returns.  If it is not empty, the response_pwc_thread()
 *     sends each of the responses in it upstream before clearing it and calling
 *     convert_response() again for the next incoming response.  If the array is empty,
 *     then m_p_nascent_response in req_rsp_info will point to the partially formed
 *     converted response.
 *
 */



using namespace std;
#if SYSTEMC_VERSION >= 20050601
using namespace sc_core;
#endif
using namespace xtsc;
using log4xtensa::INFO_LOG_LEVEL;
using log4xtensa::VERBOSE_LOG_LEVEL;





namespace xtsc_component {

static bool start_address_less_then(const xtsc_address_range_entry* range1, const xtsc_address_range_entry* range2) {
  return (range1->m_start_address8 < range2->m_start_address8);
}

}


xtsc_component::xtsc_arbiter::xtsc_arbiter(sc_module_name module_name, const xtsc_arbiter_parms& arbiter_parms) :
  sc_module             (module_name),
  m_request_port        ("m_request_port"),
  m_respond_export      ("m_respond_export"),
  m_respond_impl        ("m_respond_impl", *this),
  m_response_fifo       ("m_response_fifo", arbiter_parms.get_non_zero_u32("response_fifo_depth")),
  m_use_block_requests  (arbiter_parms.get_bool("use_block_requests")),
  m_slave_byte_width    (0),
  m_read_only           (arbiter_parms.get_bool("read_only")),
  m_write_only          (arbiter_parms.get_bool("write_only")),
  m_time_resolution     (sc_get_time_resolution()),
  m_text                (log4xtensa::TextLogger::getInstance(name())),
  m_binary              (log4xtensa::BinaryLogger::getInstance(name()))
{

  m_num_masters                 = arbiter_parms.get_non_zero_u32("num_masters");
  m_one_at_a_time               = arbiter_parms.get_bool("one_at_a_time");

  m_log_data_binary             = true;
  m_next_slot                   = 0;

  m_delay_from_receipt          = arbiter_parms.get_bool("delay_from_receipt");
  m_dram_lock                   = arbiter_parms.get_bool("dram_lock");
  m_external_cbox               = arbiter_parms.get_bool("external_cbox");
  m_xfer_en_port                = arbiter_parms.get_u32 ("xfer_en_port");
  m_immediate_timing            = arbiter_parms.get_bool("immediate_timing");
  if (m_immediate_timing) {
    m_one_at_a_time             = false;
  }

  // Get clock period 
  u32 clock_period = arbiter_parms.get_u32("clock_period");
  if (clock_period == 0xFFFFFFFF) {
    m_clock_period = xtsc_get_system_clock_period();
  }
  else {
    m_clock_period = m_time_resolution * clock_period;
  }
  m_clock_period_value  = m_clock_period.value();
  u32 posedge_offset = arbiter_parms.get_u32("posedge_offset");
  if (posedge_offset == 0xFFFFFFFF) {
    m_posedge_offset = xtsc_get_system_clock_posedge_offset();
  }
  else {
    m_posedge_offset = posedge_offset * m_time_resolution;
  }
  if (m_posedge_offset >= m_clock_period) {
    ostringstream oss;
    oss << kind() << " '" << name() << "' parameter error:" << endl;
    oss << "\"posedge_offset\" (0x" << hex << posedge_offset << "=>" << m_posedge_offset
        << ") must be strictly less than \"clock_period\" (0x" << clock_period << "=>" << m_clock_period << ")";
    throw xtsc_exception(oss.str());
  }
  m_posedge_offset_value = m_posedge_offset.value();
  m_has_posedge_offset = (m_posedge_offset != SC_ZERO_TIME);

  // Get arbitration phase
  u32 arbitration_phase = arbiter_parms.get_u32("arbitration_phase");
  if (arbitration_phase == 0xFFFFFFFF) {
    m_arbitration_phase = 0.5 * m_clock_period;
  }
  else {
    m_arbitration_phase = m_time_resolution * arbitration_phase;
  }
  if (m_arbitration_phase >= m_clock_period) {
    ostringstream oss;
    oss << "xtsc_arbiter '" << name() << "' \"arbitration_phase\"=" << m_arbitration_phase
        << " must be stricly less than \"clock_period=" << m_clock_period;
    throw xtsc_exception(oss.str());
  }
  m_arbitration_phase_plus_one = m_arbitration_phase + m_clock_period;

  m_request_delay       = m_clock_period * arbiter_parms.get_u32("request_delay");
  m_response_delay      = m_clock_period * arbiter_parms.get_u32("response_delay");
  m_response_repeat     = m_clock_period * arbiter_parms.get_u32("response_repeat");
  m_recovery_time       = m_clock_period * arbiter_parms.get_u32("recovery_time");

  u32 nacc_wait_time    = arbiter_parms.get_u32("nacc_wait_time");
  if (nacc_wait_time == 0xFFFFFFFF) {
    m_nacc_wait_time = m_clock_period;
  }
  else {
    m_nacc_wait_time = m_time_resolution * nacc_wait_time;
    if (m_nacc_wait_time > m_clock_period) {
      ostringstream oss;
      oss << "xtsc_arbiter '" << name() << "': \"nacc_wait_time\" of " << m_nacc_wait_time << " exceeds clock period of "
          << m_clock_period;
      throw xtsc_exception(oss.str());
    }
  }

  u32 mask = 0x80000000;
  bool found_one = false;
  u32 num_bits = 0;     // = ceil(log2(m_num_masters))
  for (u32 i=32; i>0; i--, mask >>= 1) {
    if (m_num_masters & mask) {
      if (found_one) {
        num_bits += 1;
        break;
      }
      num_bits = i-1;
      found_one = true;
    }
  }
  m_route_id_bits_shift = arbiter_parms.get_u32("route_id_lsb");
  m_route_id_bits_mask = ((1 << num_bits) - 1) << m_route_id_bits_shift;
  XTSC_LOG(m_text, xtsc_get_constructor_log_level(), "Using route_id mask of 0x" << hex << m_route_id_bits_mask);

  m_master_byte_widths = arbiter_parms.get_u32_vector("master_byte_widths");
  m_is_pwc = (m_master_byte_widths.size() != 0);
  if (m_is_pwc) {
    if (m_immediate_timing) {
      ostringstream oss;
      oss << "xtsc_arbiter '" << name() << "': \"immediate_timing\" must be false if \"master_byte_widths\" is set";
      throw xtsc_exception(oss.str());
    }
    if (m_master_byte_widths.size() != m_num_masters) {
      ostringstream oss;
      oss << "xtsc_arbiter '" << name() << "': size of \"master_byte_widths\" (" << m_master_byte_widths.size()
          << ") != \"num_masters\" (" << m_num_masters << ")";
      throw xtsc_exception(oss.str());
    }
    for (u32 i=0; i<m_num_masters; ++i) {
      if ((m_master_byte_widths[i] != 4) && (m_master_byte_widths[i] != 8) && (m_master_byte_widths[i] != 16)) {
        ostringstream oss;
        oss << "xtsc_arbiter '" << name() << "': master_byte_widths[" << i << "]=" << m_master_byte_widths[i]
            << " which is not one of the valid values of 4|8|16.";
        throw xtsc_exception(oss.str());
      }
    }
    m_slave_byte_width = arbiter_parms.get_u32("slave_byte_width");
    if ((m_slave_byte_width != 4) && (m_slave_byte_width != 8) && (m_slave_byte_width != 16)) {
      ostringstream oss;
      oss << "xtsc_arbiter '" << name() << "': slave_byte_width=" << m_slave_byte_width 
          << " which is not one of the valid non-default values of 4|8|16.";
      throw xtsc_exception(oss.str());
    }
  }

  m_request_exports = new sc_export<xtsc_request_if>*[m_num_masters];
  m_request_impl    = new xtsc_request_if_impl*      [m_num_masters];
  for (u32 i=0; i<m_num_masters; i++) {
    ostringstream oss1;
    oss1 << "m_request_exports[" << i << "]";
    m_request_exports[i] = new sc_export<xtsc_request_if>(oss1.str().c_str());
    ostringstream oss2;
    oss2 << "m_request_impl[" << i << "]";
    m_request_impl   [i] = new xtsc_request_if_impl(oss2.str().c_str(), *this, i);
    (*m_request_exports[i])(*m_request_impl[i]);
  }

  vector<u32> request_fifo_depths = arbiter_parms.get_u32_vector("request_fifo_depths");
  if ((request_fifo_depths.size() != 0) && (request_fifo_depths.size() != m_num_masters)) {
    ostringstream oss;
    oss << "xtsc_arbiter '" << name() << "': size of \"request_fifo_depths\" (" << request_fifo_depths.size()
        << ") != \"num_masters\" (" << m_num_masters << ")";
    throw xtsc_exception(oss.str());
  }
  u32 request_fifo_depth = arbiter_parms.get_u32("request_fifo_depth");
  m_request_deques = new deque<request_info*>*[m_num_masters];
  m_request_fifos = new sc_fifo<int>*[m_num_masters];
  for (u32 i=0; i<m_num_masters; i++) {
    ostringstream oss;
    u32 depth = (request_fifo_depths.size() ? request_fifo_depths[i] : request_fifo_depth);
    if (depth == 0) {
      ostringstream oss;
      oss << "xtsc_arbiter '" << name() << "': depth from \"request_fifo_depths\" or \"request_fifo_depth\" cannot be 0";
      throw xtsc_exception(oss.str());
    }
    m_request_deques[i] = new deque<request_info*>();
    oss << "m_request_fifos[" << i << "]";
    m_request_fifos[i] = new sc_fifo<int>(oss.str().c_str(), depth);
  }

  m_respond_ports = new sc_port<xtsc_respond_if>*[m_num_masters];
  for (u32 i=0; i<m_num_masters; i++) {
    ostringstream oss;
    oss << "m_respond_ports[" << i << "]";
    m_respond_ports[i] = new sc_port<xtsc_respond_if>(oss.str().c_str());
  }

  m_respond_export(m_respond_impl);

  if (m_dram_lock) {
    if (m_immediate_timing) {
      ostringstream oss;
      oss << kind() << " '" << name() << "' parameters \"dram_lock\" and \"immediate_timing\" cannot both be true";
      throw xtsc_exception(oss.str());
    }
    if (m_is_pwc) {
      ostringstream oss;
      oss << kind() << " '" << name() << "' parameters \"dram_lock\" cannot be true when acting as a PIF-width converter";
      throw xtsc_exception(oss.str());
    }
    for (u32 i=0; i < m_num_masters; ++i) {
      m_dram_locks.push_back(false);
    }
  }

  if (m_external_cbox) {
    if (m_immediate_timing) {
      ostringstream oss;
      oss << kind() << " '" << name() << "' parameters \"external_cbox\" and \"immediate_timing\" cannot both be true";
      throw xtsc_exception(oss.str());
    }
    if (m_is_pwc) {
      ostringstream oss;
      oss << kind() << " '" << name() << "' parameters \"external_cbox\" cannot be true when acting as a PIF-width converter";
      throw xtsc_exception(oss.str());
    }
    if (m_num_masters != 2) {
      ostringstream oss;
      oss << kind() << " '" << name() << "' parameters \"external_cbox\" cannot be true unless \"num_masters\"[="
          << m_num_masters << "] is 2.";
      throw xtsc_exception(oss.str());
    }
  }

  if (m_xfer_en_port != 0xFFFFFFFF) {
    if (m_immediate_timing) {
      ostringstream oss;
      oss << kind() << " '" << name() << "' parameters \"xfer_en_port\" and \"immediate_timing\" cannot both be set";
      throw xtsc_exception(oss.str());
    }
    if (m_is_pwc) {
      ostringstream oss;
      oss << kind() << " '" << name() << "' parameter \"xfer_en_port\" cannot be set when acting as a PIF-width converter";
      throw xtsc_exception(oss.str());
    }
    if (m_external_cbox) {
      ostringstream oss;
      oss << kind() << " '" << name() << "' parameters \"xfer_en_port\" and \"external_cbox\" cannot both be set";
      throw xtsc_exception(oss.str());
    }
  }

  // Build address translation tables?
  m_do_translation = false;
  const char *translation_file = arbiter_parms.get_c_str("translation_file");
  if (translation_file && translation_file[0]) {
    m_do_translation = true;
    for (u32 i=0; i<m_num_masters; ++i) {
      m_translation_tables.push_back(new vector<xtsc_address_range_entry*>);
    }
    xtsc_script_file    file(translation_file, "translation_file", name(), kind(), false);
    u32                 line_count;
    vector<string>      words;
    string              line;
    while ((line_count = file.get_words(words, line)) != 0) {
      u32 num_words = words.size();
      if ((num_words != 3) && (num_words != 4)) {
        ostringstream oss;
        oss << "Found " << num_words << " words (expected 3 or 4):" << endl;
        oss << line;
        oss << file.info_for_exception();
        throw xtsc_exception(oss.str());
      }
      u32 value[4];
      for (u32 i=0; i<num_words; ++i) {
        string word = words[i];
        try {
          value[i] = xtsc_strtou32(word);
        }
        catch (const xtsc_exception&) {
            ostringstream oss;
            oss << "Cannot convert word #" << i+1 << " '" << word << "' to number:" << endl;
            oss << line;
            oss << file.info_for_exception();
            throw xtsc_exception(oss.str());
        }
      }
      u32          port_num         = value[0];
      xtsc_address low_address      = value[1];
      xtsc_address high_address     = ((num_words == 4) ? value[2] : 0xFFFFFFFF);
      xtsc_address new_base_address = ((num_words == 4) ? value[3] : value[2]);
      xtsc_address delta            = new_base_address - low_address;
      if (port_num >= m_num_masters) {
        ostringstream oss;
        oss << "<PortNum>=" << port_num << " must be less than \"num_masters\"=" << m_num_masters << ":" << endl;
        oss << line;
        oss << file.info_for_exception();
        throw xtsc_exception(oss.str());
      }
      if (high_address < low_address) {
        ostringstream oss;
        oss << "<HighAddress>=0x" << hex << high_address << " cannot be less than <LowAddress>=0x" << low_address << ":" << endl;
        oss << line;
        oss << file.info_for_exception();
        throw xtsc_exception(oss.str());
      }
      xtsc_address_range_entry *p_entry = new xtsc_address_range_entry(low_address, high_address, port_num, delta);
      vector<xtsc_address_range_entry*> *p_translation_table = m_translation_tables[port_num];
      p_translation_table->push_back(p_entry);
    }
    // Sort each translation table and check for overlap
    for (u32 i=0; i<m_num_masters; ++i) {
      vector<xtsc_address_range_entry*> *p_translation_table = m_translation_tables[i];
      sort(p_translation_table->begin(), p_translation_table->end(), start_address_less_then);
      vector<xtsc_address_range_entry*>::iterator itt1 = p_translation_table->begin();
      if (itt1 != p_translation_table->end()) {
        XTSC_DEBUG(m_text, "translate: " << **itt1);
        vector<xtsc_address_range_entry*>::iterator itt2 = itt1;
        for (++itt2; itt2 != p_translation_table->end(); itt1 = itt2++) {
          XTSC_DEBUG(m_text, "translate: " << **itt2);
          if ((*itt1)->m_end_address8 >= (*itt2)->m_start_address8) {
            ostringstream oss;
            oss << kind() << " '" << name() << "':  Two address translations overlap for port #" << i << ": "
                << **itt1 << " and " << **itt2;
            throw xtsc_exception(oss.str());
          }
        }
      }
    }
  }

  if (!m_immediate_timing) {
    if (m_is_pwc) {
      SC_THREAD(arbiter_pwc_thread);
      SC_THREAD(response_pwc_thread);
    }
    else {
      SC_THREAD(arbiter_thread);
      SC_THREAD(response_thread);
    }
  }

  log4xtensa::LogLevel ll = xtsc_get_constructor_log_level();
  XTSC_LOG(m_text, ll, "Constructed xtsc_arbiter '" << name() << "':");
  XTSC_LOG(m_text, ll, " num_masters            = "   << m_num_masters);
  { ostringstream oss; if (m_is_pwc) for (u32 i=0; i<m_num_masters; ++i) oss << (i ? "," : "") << m_master_byte_widths[i];
  XTSC_LOG(m_text, ll, " master_byte_widths     = "   << oss.str());
  }
  if (m_is_pwc) {
  XTSC_LOG(m_text, ll, " slave_byte_width       = "   << m_slave_byte_width);
  XTSC_LOG(m_text, ll, " use_block_requests     = "   << boolalpha << m_use_block_requests);
  }
  XTSC_LOG(m_text, ll, " translation_file       = "   << (translation_file ? translation_file : ""));
  XTSC_LOG(m_text, ll, " dram_lock              = "   << (m_dram_lock        ? "true" : "false"));
  XTSC_LOG(m_text, ll, " external_cbox          = "   << (m_external_cbox    ? "true" : "false"));
  if (m_xfer_en_port == 0xFFFFFFFF) {
  XTSC_LOG(m_text, ll, " xfer_en_port           = 0xFFFFFFFF => (xtsc_request::get_xfer_en() will not be used)");
  } else {
  XTSC_LOG(m_text, ll, " xfer_en_port           = "   << m_xfer_en_port);
  }
  XTSC_LOG(m_text, ll, " read_only              = "   << boolalpha << m_read_only);
  XTSC_LOG(m_text, ll, " write_only             = "   << boolalpha << m_write_only);
  XTSC_LOG(m_text, ll, " immediate_timing       = "   << (m_immediate_timing ? "true" : "false"));
  XTSC_LOG(m_text, ll, " request_fifo_depth     = "   << arbiter_parms.get_u32("request_fifo_depth"));
  {
    ostringstream oss;
    for (u32 i=0; request_fifo_depths.size() && i<m_num_masters; i++) {
      if (i) oss << ",";
      oss << request_fifo_depths[i];
    }
    if (request_fifo_depths.size() && m_one_at_a_time) {
      oss << " (Did you intend to leave \"one_at_a_time\" true?)";
    }
  XTSC_LOG(m_text, ll, " request_fifo_depths    = "   << oss.str());
  }
  XTSC_LOG(m_text, ll, " response_fifo_depth    = "   << arbiter_parms.get_u32("response_fifo_depth"));
  if (!m_immediate_timing) {
  if (clock_period == 0xFFFFFFFF) {
  XTSC_LOG(m_text, ll, " clock_period           = 0xFFFFFFFF => " << m_clock_period.value() << " (" << m_clock_period << ")");
  } else {
  XTSC_LOG(m_text, ll, " clock_period           = "   << clock_period << " (" << m_clock_period << ")");
  }
  if (posedge_offset == 0xFFFFFFFF) {
  XTSC_LOG(m_text, ll, " posedge_offset         = 0xFFFFFFFF => " << m_posedge_offset.value() << " (" << m_posedge_offset << ")");
  } else {
  XTSC_LOG(m_text, ll, " posedge_offset         = "   << posedge_offset << " (" << m_posedge_offset << ")");
  }
  if (arbitration_phase == 0xFFFFFFFF) {
  XTSC_LOG(m_text, ll, " arbitration_phase      = 0xFFFFFFFF => " << m_arbitration_phase.value() << " (" << m_arbitration_phase << ")");
  } else {
  XTSC_LOG(m_text, ll, " arbitration_phase      = "   << arbitration_phase << " (" << m_arbitration_phase << ")");
  }
  if (nacc_wait_time == 0xFFFFFFFF) {
  XTSC_LOG(m_text, ll, " nacc_wait_time         = 0xFFFFFFFF => " << m_nacc_wait_time.value() << " (" << m_nacc_wait_time << ")");
  } else {
  XTSC_LOG(m_text, ll, " nacc_wait_time         = "   << nacc_wait_time << " (" << m_nacc_wait_time << ")");
  }
  XTSC_LOG(m_text, ll, " one_at_a_time          = "   << (m_one_at_a_time ? "true" : "false"));
  XTSC_LOG(m_text, ll, " delay_from_receipt     = "   << (m_delay_from_receipt ? "true" : "false"));
  XTSC_LOG(m_text, ll, " request_delay          = "   << arbiter_parms.get_u32("request_delay"));
  XTSC_LOG(m_text, ll, " response_delay         = "   << arbiter_parms.get_u32("response_delay"));
  XTSC_LOG(m_text, ll, " response_repeat        = "   << arbiter_parms.get_u32("response_repeat"));
  XTSC_LOG(m_text, ll, " recovery_time          = "   << arbiter_parms.get_u32("recovery_time"));
  }

  if (m_is_pwc) {
    for (u32 i=0; i<4; ++i) {
      m_requests[i] = NULL;
      m_responses[i] = NULL;
    }
  }

  reset(true);

}



xtsc_component::xtsc_arbiter::~xtsc_arbiter(void) {

  if (m_request_exports) {
    for (u32 i=0; i<m_num_masters; i++) {
      if (m_request_exports[i]) {
        delete m_request_exports[i];
        m_request_exports[i] = 0;
      }
    }
    delete [] m_request_exports;
    m_request_exports = 0;
  }

  if (m_request_fifos) {
    for (u32 i=0; i<m_num_masters; i++) {
      if (m_request_fifos[i]) {
        delete m_request_fifos[i];
        m_request_fifos[i] = 0;
      }
    }
    delete [] m_request_fifos;
    m_request_fifos = 0;
  }

  if (m_request_deques) {
    for (u32 i=0; i<m_num_masters; i++) {
      if (m_request_deques[i]) {
        delete m_request_deques[i];
        m_request_deques[i] = 0;
      }
    }
    delete [] m_request_deques;
    m_request_deques = 0;
  }

  if (m_respond_ports) {
    for (u32 i=0; i<m_num_masters; i++) {
      if (m_respond_ports[i]) {
        delete m_respond_ports[i];
        m_respond_ports[i] = 0;
      }
    }
    delete [] m_respond_ports;
    m_respond_ports = 0;
  }

  // Delete each xtsc_address_range_entry and each translation table
  if (m_do_translation) {
    for (u32 i=0; i<m_num_masters; ++i) {
      vector<xtsc_address_range_entry*> *p_translation_table = m_translation_tables[i];
      vector<xtsc_address_range_entry*>::iterator itt = p_translation_table->begin();
      for (; itt != p_translation_table->end(); ++itt) {
        xtsc_address_range_entry *p_entry = *itt;
        delete p_entry;
      }
      delete p_translation_table;
    }
  }
}



void xtsc_component::xtsc_arbiter::reset(bool /*hard_reset*/) {
  XTSC_INFO(m_text, "xtsc_arbiter::reset()");

  m_last_request_time_stamp     = SC_ZERO_TIME - (m_delay_from_receipt ? m_recovery_time : m_request_delay);
  m_last_response_time_stamp    = SC_ZERO_TIME - (m_delay_from_receipt ? m_recovery_time : m_request_delay);

  m_waiting_for_nacc            = false;
  m_request_got_nacc            = false;
  m_token                       = m_num_masters - 1;
  m_lock                        = false;

  if (m_is_pwc) {
    m_pending_request_id        = m_num_slots;  // Indicates there is no pending request
    m_active_block_read_id      = m_num_slots;  // Indicates no BLOCK_READ response is in progress
    for (u8 i=0; i<m_num_slots; ++i) {
      m_req_rsp_table[i] = NULL;
    }
    for (u32 i=0; (m_requests[i] != NULL) && (i<4); ++i) {
      delete_request_info(m_requests[i]);
    }
    for (u32 i=0; (m_responses[i] != NULL) && (i<4); ++i) {
      delete_response_info(m_responses[i]);
    }
  }

  if (m_dram_lock) {
    for (u32 i=0; i < m_num_masters; ++i) {
      m_dram_locks[i] = false;
    }
  }

}



void xtsc_component::xtsc_arbiter::connect(xtsc_arbiter& arbiter, u32 port_num) {
  if (port_num >= m_num_masters) {
    ostringstream oss;
    oss << kind() << " '" << name() << "':  Invalid port_num specified to xtsc_arbiter::connect():  port_num=" << port_num;
    oss << ".  Valid range is 0 to " << (m_num_masters - 1) << ".";
    throw xtsc_exception(oss.str());
  }
  arbiter.m_request_port(*m_request_exports[port_num]);
  (*m_respond_ports[port_num])(arbiter.m_respond_export);
}



void xtsc_component::xtsc_arbiter::connect(xtsc_cohctrl& cohctrl, xtsc_cohctrl::port_type type, u32 cohctrl_port, u32 arbiter_port) {
  u32 num_clients = cohctrl.get_num_clients();
  if ((type != xtsc_cohctrl::PT_CLIENT) && (arbiter_port >= m_num_masters)) {
    ostringstream oss;
    oss << kind() << " '" << name() << "':  Invalid arbiter_port specified to xtsc_arbiter::connect():  arbiter_port=" << arbiter_port;
    oss << ".  Valid range is 0 to " << (m_num_masters - 1) << ".";
    throw xtsc_exception(oss.str());
  }
  if ((type != xtsc_cohctrl::PT_MEMORY) && (cohctrl_port >= num_clients)) {
    ostringstream oss;
    oss << "Invalid cohctrl_port=" << cohctrl_port << " in connect(): " << endl;
    oss << cohctrl.kind() << " '" << cohctrl.name() << "' has " << num_clients
        << " ports numbered from 0 to " << num_clients-1 << endl;
    throw xtsc_exception(oss.str());
  }
  if (type == xtsc_cohctrl::PT_SNOOP) {
    (*cohctrl.m_snoop_ports[cohctrl_port])(*m_request_exports[arbiter_port]);
    (*m_respond_ports[arbiter_port])(*cohctrl.m_snoop_exports[cohctrl_port]);
  }
  else if (type == xtsc_cohctrl::PT_MEMORY) {
    cohctrl.m_request_port(*m_request_exports[arbiter_port]);
    (*m_respond_ports[arbiter_port])(cohctrl.m_respond_export);
  }
  else if (type == xtsc_cohctrl::PT_CLIENT) {
    m_request_port(*cohctrl.m_client_exports[cohctrl_port]);
    (*cohctrl.m_client_ports[cohctrl_port])(m_respond_export);
  }
  else {
    ostringstream oss;
    oss << kind() << " '" << name() << "':  Invalid xtsc_cohctrl::port_type specified to xtsc_arbiter::connect()";
    throw xtsc_exception(oss.str());
  }
}



void xtsc_component::xtsc_arbiter::connect(xtsc_core& core, const char *memory_port_name, u32 port_num) {
  string lc = (memory_port_name ? memory_port_name : "");
  transform(lc.begin(), lc.end(), lc.begin(), ::tolower);
  if (lc == "inbound_pif" || lc == "snoop") {
    m_request_port(core.get_request_export(memory_port_name));
    core.get_respond_port(memory_port_name)(m_respond_export);
  }
  else {
    if (port_num >= m_num_masters) {
      ostringstream oss;
      oss << "xtsc_arbiter '" << name() << "':  Invalid port_num specified to xtsc_arbiter::connect():  port_num=" << port_num;
      oss << ".  Valid range is 0 to " << (m_num_masters - 1) << ".";
      throw xtsc_exception(oss.str());
    }
    core.get_request_port(memory_port_name)(*m_request_exports[port_num]);
    (*m_respond_ports[port_num])(core.get_respond_export(memory_port_name));
  }
}



void xtsc_component::xtsc_arbiter::connect(xtsc_dma_engine& dma_engine, u32 port_num) {
  if (port_num >= m_num_masters) {
    ostringstream oss;
    oss << kind() << " '" << name() << "':  Invalid port_num specified to xtsc_arbiter::connect():  port_num=" << port_num;
    oss << ".  Valid range is 0 to " << (m_num_masters - 1) << ".";
    throw xtsc_exception(oss.str());
  }
  dma_engine.m_request_port(*m_request_exports[port_num]);
  (*m_respond_ports[port_num])(dma_engine.m_respond_export);
}



void xtsc_component::xtsc_arbiter::connect(xtsc_master& master, u32 port_num) {
  if (port_num >= m_num_masters) {
    ostringstream oss;
    oss << kind() << " '" << name() << "':  Invalid port_num specified to xtsc_arbiter::connect():  port_num=" << port_num;
    oss << ".  Valid range is 0 to " << (m_num_masters - 1) << ".";
    throw xtsc_exception(oss.str());
  }
  master.m_request_port(*m_request_exports[port_num]);
  (*m_respond_ports[port_num])(master.m_respond_export);
}



void xtsc_component::xtsc_arbiter::connect(xtsc_memory_trace& memory_trace, u32 trace_port, u32 arbiter_port) {
  u32 num_slaves = memory_trace.get_num_ports();
  if (trace_port >= num_slaves) {
    ostringstream oss;
    oss << "Invalid trace_port=" << trace_port << " in connect(): " << endl;
    oss << memory_trace.kind() << " '" << memory_trace.name() << "' has " << num_slaves << " ports numbered from 0 to "
        << num_slaves-1 << endl;
    throw xtsc_exception(oss.str());
  }
  if (arbiter_port >= m_num_masters) {
    ostringstream oss;
    oss << kind() << " '" << name() << "':  Invalid arbiter_port specified to xtsc_arbiter::connect():  arbiter_port=" << arbiter_port;
    oss << ".  Valid range is 0 to " << (m_num_masters - 1) << ".";
    throw xtsc_exception(oss.str());
  }
  (*memory_trace.m_request_ports[trace_port])(*m_request_exports[arbiter_port]);
  (*m_respond_ports[arbiter_port])(*memory_trace.m_respond_exports[trace_port]);
}



void xtsc_component::xtsc_arbiter::connect(xtsc_pin2tlm_memory_transactor& pin2tlm, u32 tran_port, u32 arbiter_port) {
  u32 num_slaves = pin2tlm.get_num_ports();
  if (tran_port >= num_slaves) {
    ostringstream oss;
    oss << "Invalid tran_port=" << tran_port << " in connect(): " << endl;
    oss << pin2tlm.kind() << " '" << pin2tlm.name() << "' has " << num_slaves << " ports numbered from 0 to " << num_slaves-1 << endl;
    throw xtsc_exception(oss.str());
  }
  if (arbiter_port >= m_num_masters) {
    ostringstream oss;
    oss << kind() << " '" << name() << "':  Invalid arbiter_port specified to xtsc_arbiter::connect():  arbiter_port=" << arbiter_port;
    oss << ".  Valid range is 0 to " << (m_num_masters - 1) << ".";
    throw xtsc_exception(oss.str());
  }
  (*pin2tlm.m_request_ports[tran_port])(*m_request_exports[arbiter_port]);
  (*m_respond_ports[arbiter_port])(*pin2tlm.m_respond_exports[tran_port]);
}



void xtsc_component::xtsc_arbiter::connect(xtsc_router& router, u32 router_port, u32 arbiter_port) {
  u32 num_slaves = router.get_num_slaves();
  if (router_port >= num_slaves) {
    ostringstream oss;
    oss << "Invalid router_port=" << router_port << " in connect(): " << endl;
    oss << router.kind() << " '" << router.name() << "' has " << num_slaves << " ports numbered from 0 to " << num_slaves-1 << endl;
    throw xtsc_exception(oss.str());
  }
  if (arbiter_port >= m_num_masters) {
    ostringstream oss;
    oss << kind() << " '" << name() << "':  Invalid arbiter_port specified to xtsc_arbiter::connect():  arbiter_port=" << arbiter_port;
    oss << ".  Valid range is 0 to " << (m_num_masters - 1) << ".";
    throw xtsc_exception(oss.str());
  }
  (*router.m_request_ports[router_port])(*m_request_exports[arbiter_port]);
  (*m_respond_ports[arbiter_port])(*router.m_respond_exports[router_port]);
}



void xtsc_component::xtsc_arbiter::arbiter_thread(void) {

  try {

    while (true) {
      XTSC_DEBUG(m_text, "arbiter_thread going to sleep.");
      wait(m_arbiter_thread_event);
      XTSC_DEBUG(m_text, "arbiter_thread woke up.");
      bool request_found;
      do {
        // Sync to arbitration phase of clock
        sc_time now = sc_time_stamp();
        sc_time phase_now = (now.value() % m_clock_period_value) * m_time_resolution;
        if (m_has_posedge_offset) {
          if (phase_now < m_posedge_offset) {
            phase_now += m_clock_period;
          }
          phase_now -= m_posedge_offset;
        }
        if (phase_now > m_arbitration_phase) {
          wait(m_arbitration_phase_plus_one - phase_now);
        }
        else if (phase_now < m_arbitration_phase) {
          wait(m_arbitration_phase - phase_now);
        }
        XTSC_DEBUG(m_text, "arbiter_thread starting arbitration.");
        u32 port_num = m_token;
        request_found = false;
        // Perform arbitration 
        do {
          if (!m_lock) {
            port_num = (port_num + 1) % m_num_masters;
          }
          XTSC_DEBUG(m_text, "arbiter_thread() port_num=" << port_num << " m_token=" << m_token << 
                             " num_available()=" << m_request_fifos[port_num]->num_available());
          if (m_request_fifos[port_num]->num_available()) {
            // Get our current transaction
            request_info *p_request_info = m_request_deques[port_num]->front();
            // If operating as external CBox then decide if we have a simultaneous read/write to same address situation
            if (m_external_cbox && (p_request_info->m_request.get_type() == xtsc_request::WRITE) && !m_lock) {
              u32 other_port = ((port_num == 0) ? 1 : 0);
              if (m_request_fifos[other_port]->num_available()) {
                request_info *p_other_request_info = m_request_deques[other_port]->front();
                if (p_other_request_info->m_request.get_type() == xtsc_request::READ) {
                  xtsc_address  wr_beg = p_request_info      ->m_request.get_byte_address();
                  xtsc_address  rd_beg = p_other_request_info->m_request.get_byte_address();
                  u32           wr_end = p_request_info      ->m_request.get_byte_size() + wr_beg - 1;
                  u32           rd_end = p_other_request_info->m_request.get_byte_size() + rd_beg - 1;
                  if ((wr_end >= rd_beg) && (rd_end >= wr_beg)) {
                    // Other port has a READ to an overlapping address => switch to that port to give the READ priority
                    port_num = other_port;
                    p_request_info = p_other_request_info;
                  }
                }
              }
            }
            else if ((m_xfer_en_port != 0xFFFFFFFF) && (m_xfer_en_port != port_num)) {
              if (m_request_fifos[m_xfer_en_port]->num_available()) {
                request_info *p_other_request_info = m_request_deques[m_xfer_en_port]->front();
                if (p_other_request_info->m_request.get_xfer_en()) {
                  // The designated port has an xfer_en request => switch to that port to give it priority
                  port_num = m_xfer_en_port;
                  p_request_info = p_other_request_info;
                }
              }
            }
            m_request_deques[port_num]->pop_front();
            int dummy;
            m_request_fifos[port_num]->nb_read(dummy);
            request_found = true;
            XTSC_DEBUG(m_text, "arbiter_thread() got: " << p_request_info->m_request);
            if (!m_one_at_a_time) {
              // Calculate delay (net => No Earlier Than time)
              sc_time receipt_net       = p_request_info->m_time_stamp + m_request_delay;
              sc_time last_request_net  = m_last_request_time_stamp + (m_delay_from_receipt ? m_recovery_time : m_request_delay);
              sc_time latest_net        = (receipt_net > last_request_net) ? receipt_net : last_request_net;
              sc_time now               = sc_time_stamp();
              sc_time delay             = (latest_net <= now) ? SC_ZERO_TIME : (latest_net - now);
              XTSC_DEBUG(m_text, "arbiter_thread() doing wait for " << delay);
              wait(delay);
              XTSC_DEBUG(m_text, "arbiter_thread() done with wait");
            }
            m_token = port_num;
            if (m_dram_lock) {
              m_lock = m_dram_locks[port_num];
            }
            else {
              m_lock = !p_request_info->m_request.get_last_transfer();
            }
            handle_request(p_request_info, port_num);
          }
          else if (m_lock && m_one_at_a_time) {
            nacc_remaining_requests();
          }
          if (m_lock && (m_xfer_en_port != 0xFFFFFFFF)) {
            ostringstream oss;
            oss << kind() << " '" << name() << "' is locked to a port but \"xfer_en_port\" was set.  This is not allowed.";
            throw xtsc_exception(oss.str());
          }
        } while (port_num != m_token);
      } while (request_found);
    }

  }
  catch (const exception& error) {
    ostringstream oss;
    oss << "std::exception caught in arbiter_thread of " << kind() << " '" << name() << "'." << endl;
    oss << "what(): " << error.what() << endl;
    xtsc_log_multiline(m_text, log4xtensa::FATAL_LOG_LEVEL, oss.str(), 2);
    throw;
  }

}



void xtsc_component::xtsc_arbiter::arbiter_pwc_thread(void) {

  try {

    while (true) {
      XTSC_DEBUG(m_text, "arbiter_pwc_thread going to sleep.");
      wait(m_arbiter_thread_event);
      XTSC_DEBUG(m_text, "arbiter_pwc_thread woke up.");
      bool request_found;
      do {
        // Sync to arbitration phase of clock
        sc_time now = sc_time_stamp();
        sc_time phase_now = (now.value() % m_clock_period_value) * m_time_resolution;
        if (m_has_posedge_offset) {
          if (phase_now < m_posedge_offset) {
            phase_now += m_clock_period;
          }
          phase_now -= m_posedge_offset;
        }
        if (phase_now > m_arbitration_phase) {
          wait(m_arbitration_phase_plus_one - phase_now);
        }
        else if (phase_now < m_arbitration_phase) {
          wait(m_arbitration_phase - phase_now);
        }
        XTSC_DEBUG(m_text, "arbiter_pwc_thread starting arbitration.");
        u32 port_num = m_token;
        request_found = false;
        // Perform arbitration 
        do {
          if (!m_lock) {
            port_num = (port_num + 1) % m_num_masters;
          }
          XTSC_DEBUG(m_text, "arbiter_pwc_thread() port_num=" << port_num << " m_token=" << m_token << 
                             " num_available()=" << m_request_fifos[port_num]->num_available());
          if (m_request_fifos[port_num]->num_available()) {
            // Get our current transaction
            request_info *p_request_info = m_request_deques[port_num]->front();
            m_request_deques[port_num]->pop_front();
            int dummy;
            m_request_fifos[port_num]->nb_read(dummy);
            request_found = true;
            m_token = port_num;
            m_lock = !p_request_info->m_request.get_last_transfer();
            XTSC_DEBUG(m_text, "arbiter_pwc_thread() got: " << p_request_info->m_request);

            u32 master_byte_width = m_master_byte_widths[port_num];

            if (master_byte_width == m_slave_byte_width) {
              m_requests[0] = p_request_info;
            }
            else {
              convert_request(p_request_info, master_byte_width, port_num);
            }

            for (u32 i=0; (m_requests[i] != NULL) && (i<4); ++i) {
              if (!m_one_at_a_time) {
                // Calculate delay (net => No Earlier Than time)
                sc_time receipt_net       = m_requests[i]->m_time_stamp + m_request_delay;
                sc_time last_request_net  = m_last_request_time_stamp + (m_delay_from_receipt ? m_recovery_time : m_request_delay);
                sc_time latest_net        = (receipt_net > last_request_net) ? receipt_net : last_request_net;
                sc_time now               = sc_time_stamp();
                sc_time delay             = (latest_net <= now) ? SC_ZERO_TIME : (latest_net - now);
                XTSC_DEBUG(m_text, "arbiter_pwc_thread() doing wait for " << delay);
                wait(delay);
                XTSC_DEBUG(m_text, "arbiter_pwc_thread() done with wait");
              }
              handle_request(m_requests[i], port_num);
            }
          }
          else if (m_lock && m_one_at_a_time) {
            nacc_remaining_requests();
          }
        } while (port_num != m_token);
      } while (request_found);
    }

  }
  catch (const exception& error) {
    ostringstream oss;
    oss << "std::exception caught in arbiter_pwc_thread of " << kind() << " '" << name() << "'." << endl;
    oss << "what(): " << error.what() << endl;
    xtsc_log_multiline(m_text, log4xtensa::FATAL_LOG_LEVEL, oss.str(), 2);
    throw;
  }

}



void xtsc_component::xtsc_arbiter::convert_request(request_info*& p_request_info, u32 master_byte_width, u32 port_num) {
  req_rsp_info         *p_req_rsp_info  = NULL;
  bool                  first_transfer  = (m_pending_request_id == m_num_slots);
  xtsc_request::type_t  type            = p_request_info->m_request.get_type();
  u32                   size            = p_request_info->m_request.get_byte_size();

  XTSC_DEBUG(m_text, "Converting from " << master_byte_width << "-byte PIF: " << p_request_info->m_request);

  if ((type != xtsc_request::READ       ) &&
      (type != xtsc_request::BLOCK_READ ) &&
      (type != xtsc_request::WRITE      ) &&
      (type != xtsc_request::BLOCK_WRITE) &&
      (type != xtsc_request::RCW        ))
  {
    ostringstream oss;
    oss << kind() << " '" << name() << "' received a " << xtsc_request::get_type_name(type)
        << " request which is not supported for PIF width conversion: " << p_request_info->m_request;
    throw xtsc_exception(oss.str());
  }

  if ((type == xtsc_request::RCW) && (size > m_slave_byte_width)) {
    ostringstream oss;
    oss << kind() << " '" << name() << "' received a RCW request with a size greater than downstream PIF width ("
        << m_slave_byte_width << "): " << p_request_info->m_request;
    throw xtsc_exception(oss.str());
  }

  if (first_transfer) {
    u8 request_id = get_empty_slot();
    XTSC_DEBUG(m_text, "convert_request() changing id=" << (u32) p_request_info->m_request.get_id() << " to id=" << (u32) request_id);
    p_req_rsp_info = new_req_rsp_info(p_request_info);
    m_req_rsp_table[request_id] = p_req_rsp_info;
    p_req_rsp_info->m_slot = request_id;
    request_info *p_req_info = new_request_info(*p_request_info);
    p_req_info->m_request.set_id(request_id);

    p_req_rsp_info->m_num_last_xfer_rsp_expected = 1;   // Overrides below

    if (!p_request_info->m_request.get_last_transfer()) {
      m_pending_request_id = request_id;
    }
    if (master_byte_width > m_slave_byte_width) {
      // Master is wider than slave
      m_requests[0] = p_req_info;
      if (type == xtsc_request::READ) {
        if (size > m_slave_byte_width) {
          p_req_info->m_request.set_byte_size(m_slave_byte_width);
          xtsc_byte_enables     mask    = ((size == 8) ? 0xFF : 0xFFFF);
          xtsc_byte_enables     be      = p_request_info->m_request.get_byte_enables();
          u32                   reps    = size / m_slave_byte_width;
          // Optionally use BLOCK_READ if all bytes are enabled
          if (m_use_block_requests && ((be & mask) == mask)) {
            p_req_info->m_request.set_type(xtsc_request::BLOCK_READ);
            p_req_info->m_request.set_num_transfers(reps);
            p_req_info->m_request.set_byte_enables((m_slave_byte_width == 4) ? 0xF : 0xFF);
          }
          else {
            xtsc_byte_enables slave_mask = ((m_slave_byte_width == 4) ? 0xF : 0xFF);
            p_req_info->m_request.set_byte_enables(be & slave_mask);
            xtsc_address address8 = p_req_info->m_request.get_byte_address();
            p_req_rsp_info->m_num_last_xfer_rsp_expected = reps;
            for (u32 i=1; i < reps; ++i) {
              m_requests[i] = new_request_info(*p_req_info);
              be >>= m_slave_byte_width;
              address8 += m_slave_byte_width;
              m_requests[i]->m_request.set_byte_address(address8);
              m_requests[i]->m_request.set_byte_enables(be & slave_mask);
            }
          }
        }
      }
      else if (type == xtsc_request::BLOCK_READ) {
        u32 total_bytes   = master_byte_width * p_request_info->m_request.get_num_transfers();
        u32 num_transfers = total_bytes / m_slave_byte_width;
        u32 reps          = (num_transfers + 15) / 16;
        p_req_info->m_request.set_byte_size(m_slave_byte_width);
        p_req_info->m_request.set_num_transfers(num_transfers < 16 ? num_transfers : 16);
        p_req_info->m_request.set_byte_enables((m_slave_byte_width == 4) ? 0xF : 0xFF);
        xtsc_address address8 = p_req_info->m_request.get_byte_address();
        p_req_rsp_info->m_num_last_xfer_rsp_expected = reps;
        for (u32 i=1; i < reps; ++i) {
          m_requests[i] = new_request_info(*p_req_info);
          address8 += m_slave_byte_width * 16;
          m_requests[i]->m_request.set_byte_address(address8);
        }
      }
      else if (type == xtsc_request::WRITE) {
        if (size > m_slave_byte_width) {
          p_req_info->m_request.set_byte_size(m_slave_byte_width);
          xtsc_byte_enables     mask    = ((size == 8) ? 0xFF : 0xFFFF);
          xtsc_byte_enables     be      = p_request_info->m_request.get_byte_enables();
          const u8             *p_src   = p_request_info->m_request.get_buffer();
          u32                   reps    = size / m_slave_byte_width;
          // Optionally use BLOCK_WRITE if all bytes are enabled
          if (m_use_block_requests && ((be & mask) == mask)) {
            p_req_info->m_request.set_type(xtsc_request::BLOCK_WRITE);
            p_req_info->m_request.set_last_transfer(false);
            p_req_info->m_request.set_num_transfers(reps);
            p_req_info->m_request.set_byte_enables((m_slave_byte_width == 4) ? 0xF : 0xFF);
            xtsc_address address8 = p_req_info->m_request.get_byte_address();
            for (u32 i=1; i < reps; ++i) {
              m_requests[i] = new_request_info(*p_req_info);
              p_src += m_slave_byte_width;
              m_requests[i]->m_request.set_buffer(m_slave_byte_width, p_src);
              address8 += m_slave_byte_width;
              m_requests[i]->m_request.set_byte_address(address8);
            }
            m_requests[reps-1]->m_request.set_last_transfer(true);
          }
          else {
            xtsc_byte_enables slave_mask = ((m_slave_byte_width == 4) ? 0xF : 0xFF);
            p_req_info->m_request.set_byte_enables(be & slave_mask);
            xtsc_address address8 = p_req_info->m_request.get_byte_address();
            p_req_rsp_info->m_num_last_xfer_rsp_expected = reps;
            for (u32 i=1; i < reps; ++i) {
              m_requests[i] = new_request_info(*p_req_info);
              be >>= m_slave_byte_width;
              address8 += m_slave_byte_width;
              p_src += m_slave_byte_width;
              m_requests[i]->m_request.set_byte_address(address8);
              m_requests[i]->m_request.set_buffer(m_slave_byte_width, p_src);
              m_requests[i]->m_request.set_byte_enables(be & slave_mask);
            }
          }
        }
      }
      else if (type == xtsc_request::BLOCK_WRITE) {
        u32             total_bytes     = master_byte_width * p_request_info->m_request.get_num_transfers();
        u32             num_transfers   = total_bytes / m_slave_byte_width;
        u32             reps            = master_byte_width / m_slave_byte_width;
        const u8       *p_src           = p_request_info->m_request.get_buffer();
        p_req_info->m_request.set_byte_size(m_slave_byte_width);
        p_req_info->m_request.set_num_transfers(num_transfers < 16 ? num_transfers : 16);
        p_req_info->m_request.set_byte_enables((m_slave_byte_width == 4) ? 0xF : 0xFF);
        p_req_rsp_info->m_num_last_xfer_rsp_expected = (num_transfers <= 16 ? 1 : (num_transfers / 16));
        p_req_rsp_info->m_block_write_address = p_req_info->m_request.get_byte_address() + m_slave_byte_width;
        for (u32 i=1; i < reps; ++i) {
          m_requests[i] = new_request_info(*p_req_info);
          p_src += m_slave_byte_width;
          m_requests[i]->m_request.set_buffer(m_slave_byte_width, p_src);
          m_requests[i]->m_request.set_byte_address(p_req_rsp_info->m_block_write_address);
          p_req_rsp_info->m_block_write_address += m_slave_byte_width;
        }
        p_req_rsp_info->m_num_block_write_requests = reps;
      }
      else if (type == xtsc_request::RCW) {
        xtsc_byte_enables be         = p_request_info->m_request.get_byte_enables();
        xtsc_byte_enables slave_mask = ((m_slave_byte_width == 4) ? 0xF : 0xFF);
        p_req_info->m_request.set_byte_enables(be & slave_mask);
      }
    }
    else {
      // Slave is wider than master
      if ((type == xtsc_request::READ) || (type == xtsc_request::WRITE) || (type == xtsc_request::RCW)) {
        m_requests[0] = p_req_info;
      }
      else if (type == xtsc_request::BLOCK_READ) {
        m_requests[0] = p_req_info;
        u32 total_bytes = master_byte_width * p_request_info->m_request.get_num_transfers();
        if (total_bytes <= m_slave_byte_width) {
          p_req_info->m_request.set_byte_size(total_bytes);
          p_req_info->m_request.set_type(xtsc_request::READ);
          p_req_info->m_request.set_num_transfers(1);
          p_req_info->m_request.set_byte_enables((total_bytes == 16) ? 0xFFFF : 0xFF);
        }
        else {
          p_req_info->m_request.set_byte_size(m_slave_byte_width);
          p_req_info->m_request.set_num_transfers(total_bytes / m_slave_byte_width);
          p_req_info->m_request.set_byte_enables((m_slave_byte_width == 16) ? 0xFFFF : 0xFF);
        }
      }
      else if (type == xtsc_request::BLOCK_WRITE) {
        p_req_rsp_info->m_p_nascent_request = p_req_info;
        u32 total_bytes = master_byte_width * p_request_info->m_request.get_num_transfers();
        p_req_rsp_info->m_block_write_address = p_req_info->m_request.get_byte_address();
        if (total_bytes <= m_slave_byte_width) {
          p_req_info->m_request.set_byte_size(total_bytes);
          p_req_info->m_request.set_type(xtsc_request::WRITE);
          p_req_info->m_request.set_num_transfers(1);
          p_req_info->m_request.set_byte_enables((total_bytes == 16) ? 0xFFFF : 0xFF);
        }
        else {
          p_req_info->m_request.set_byte_size(m_slave_byte_width);
          p_req_info->m_request.set_num_transfers(total_bytes / m_slave_byte_width);
          p_req_info->m_request.set_byte_enables((m_slave_byte_width == 16) ? 0xFFFF : 0xFF);
        }
        p_req_rsp_info->m_num_block_write_requests = 1;
      }
    }
  }
  else {
    // Non-first transfer (BLOCK_WRITE or RCW)
    p_req_rsp_info = m_req_rsp_table[m_pending_request_id];
    xtsc_request::type_t original_type = p_req_rsp_info->m_p_first_request_info->m_request.get_type();
    if (type != original_type) {
      ostringstream oss;
      oss << "Expected " << xtsc_request::get_type_name(original_type) << " request but received: " << p_request_info->m_request;
      throw xtsc_exception(oss.str());
    }

    if (type == xtsc_request::RCW) {
      request_info *p_req_info = new_request_info(*p_request_info);
      p_req_info->m_request.set_id(m_pending_request_id);
      m_requests[0] = p_req_info;
    }
    else if (type == xtsc_request::BLOCK_WRITE) {
      u32 total_bytes = master_byte_width * p_request_info->m_request.get_num_transfers();
      if (master_byte_width > m_slave_byte_width) {
        // Master is wider than slave
        request_info *p_req_info = new_request_info(*p_request_info);
        p_req_info->m_request.set_id(m_pending_request_id);
        m_requests[0] = p_req_info;
        u32             num_transfers   = total_bytes / m_slave_byte_width;
        u32             reps            = master_byte_width / m_slave_byte_width;
        const u8       *p_src           = p_request_info->m_request.get_buffer();
        p_req_info->m_request.set_byte_address(p_req_rsp_info->m_block_write_address);
        p_req_rsp_info->m_block_write_address += m_slave_byte_width;
        p_req_info->m_request.set_byte_size(m_slave_byte_width);
        p_req_info->m_request.set_num_transfers(num_transfers < 16 ? num_transfers : 16);
        p_req_info->m_request.set_byte_enables((m_slave_byte_width == 4) ? 0xF : 0xFF);
        p_req_info->m_request.set_last_transfer(false);
        for (u32 i=1; i < reps; ++i) {
          m_requests[i] = new_request_info(*p_req_info);
          p_src += m_slave_byte_width;
          m_requests[i]->m_request.set_buffer(m_slave_byte_width, p_src);
          m_requests[i]->m_request.set_byte_address(p_req_rsp_info->m_block_write_address);
          p_req_rsp_info->m_block_write_address += m_slave_byte_width;
        }
        p_req_rsp_info->m_num_block_write_requests += reps;
        if (p_request_info->m_request.get_last_transfer() || ((p_req_rsp_info->m_num_block_write_requests % 16) == 0)) {
          m_requests[reps-1]->m_request.set_last_transfer(true);
        }
      }
      else {
        // Slave is wider than master
        request_info   *p_req_info      = p_req_rsp_info->m_p_nascent_request;
        u32             ratio           = m_slave_byte_width / master_byte_width ;
        u32             offset          = (p_req_rsp_info->m_num_block_write_requests % ratio) * master_byte_width;
        u32             next_offset     = offset + master_byte_width;
        u8             *p_dst           = p_req_info->m_request.get_buffer();
        const u8       *p_src           = p_request_info->m_request.get_buffer();
        bool            last            = p_request_info->m_request.get_last_transfer();
        memcpy(p_dst + offset, p_src, master_byte_width);
        if (last) {
          p_req_info->m_request.set_last_transfer(true);
        }
        p_req_rsp_info->m_num_block_write_requests += 1;
        if ((next_offset == m_slave_byte_width) || (next_offset == total_bytes)) {
          p_req_info->m_request.set_byte_address(p_req_rsp_info->m_block_write_address);
          p_req_rsp_info->m_block_write_address += m_slave_byte_width;
          m_requests[0] = p_req_info;
          p_req_rsp_info->m_p_nascent_request = (last ? NULL : new_request_info(*p_req_rsp_info->m_p_nascent_request));
          m_requests[0]->m_time_stamp = p_request_info->m_time_stamp;
        }
      }
    }
    else {
      ostringstream oss;
      oss << "Program Bug: Only RCW|BLOCK_WRITE expected at line " << __LINE__ << " of " << __FILE__;
      throw xtsc_exception(oss.str());
    }

    if (p_request_info->m_request.get_last_transfer()) {
      m_pending_request_id = m_num_slots;
    }

    // Note: When first_transfer is true p_request_info is deleted (as m_p_first_request_info) in delete_req_rsp_info()
    delete_request_info(p_request_info);
  }

}



u8 xtsc_component::xtsc_arbiter::get_empty_slot() {
  bool found = false;
  u8 empty_slot = m_next_slot;
  for (; empty_slot < m_next_slot + m_num_slots; ++empty_slot) {
    if (m_req_rsp_table[empty_slot % m_num_slots] == NULL) {
      found = true;
      break;
    }
  }
  if (!found) {
    ostringstream oss;
    oss << "ERROR: " << kind() << " '" << name() << "' has run out of request ID's";
    throw xtsc_exception(oss.str());
  }
  m_next_slot = (empty_slot + 1) % m_num_slots;
  XTSC_DEBUG(m_text, "get_empty_slot() returning " << (u32) empty_slot << " m_next_slot=" << (u32) m_next_slot);
  return empty_slot;
}



void xtsc_component::xtsc_arbiter::handle_request(request_info*& p_active_request_info, u32 port_num) {
  xtsc_request *p_request = &p_active_request_info->m_request;
  add_route_id_bits(*p_request, port_num);
  u32 tries = 0;
  do {
    if (m_one_at_a_time) {
      // If we only support one request at a time, then RSP_NACC all other requests that came
      // while we were sleeping or waiting for the arbitration phase or waiting for nacc
      nacc_remaining_requests();
    }
    m_request_got_nacc = false;
    tries += 1;
    XTSC_INFO(m_text, *p_request << " Port #" << port_num << (m_lock ? " Lock" : " ") << " Try #" << tries);
    xtsc_log_memory_request_event(m_binary, INFO_LOG_LEVEL, false, 0, m_log_data_binary, *p_request);
    m_waiting_for_nacc = true;
    m_request_port->nb_request(*p_request);
    if (m_immediate_timing) break;
    m_last_request_time_stamp = sc_time_stamp();
    XTSC_DEBUG(m_text, "arbiter_thread waiting for nacc wait time =" << m_nacc_wait_time);
    wait(m_nacc_wait_time);
    XTSC_DEBUG(m_text, "arbiter_thread finished nacc wait time");
    m_waiting_for_nacc = false;
  } while (m_request_got_nacc);
  delete_request_info(p_active_request_info);
}



void xtsc_component::xtsc_arbiter::nacc_remaining_requests() {
  for (u32 port_num=0; port_num<m_num_masters; ++port_num) {
    while (m_request_fifos[port_num]->num_available()) {
      request_info *p_request_info = m_request_deques[port_num]->front();
      m_request_deques[port_num]->pop_front();
      int dummy;
      m_request_fifos[port_num]->nb_read(dummy);
      xtsc_response response(p_request_info->m_request, xtsc_response::RSP_NACC);
      XTSC_VERBOSE(m_text, response << " Port #" << port_num << " (Busy)");
      xtsc_log_memory_response_event(m_binary, VERBOSE_LOG_LEVEL, false, port_num, false, response);
      (*m_respond_ports[port_num])->nb_respond(response);
      delete_request_info(p_request_info);
    }
  }
}



void xtsc_component::xtsc_arbiter::response_thread(void) {

  try {

    while (true) {
      wait(m_response_thread_event);
      XTSC_DEBUG(m_text, "response_thread woke up.");
      while (m_response_fifo.num_available()) {
        response_info *p_response_info;
        m_response_fifo.nb_read(p_response_info);
        u32 port_num = get_port_from_response(p_response_info->m_response);
        // Calculate delay (net => No Earlier Than time)
        sc_time receipt_net       = p_response_info->m_time_stamp + m_response_delay;
        sc_time last_response_net = m_last_response_time_stamp + (m_delay_from_receipt ? m_recovery_time : m_response_delay);
        sc_time latest_net        = (receipt_net > last_response_net) ? receipt_net : last_response_net;
        sc_time now               = sc_time_stamp();
        sc_time delay = (latest_net <= now) ? SC_ZERO_TIME : (latest_net - now);
        XTSC_DEBUG(m_text, "response_thread() doing wait for " << delay);
        wait(delay);
        // Forward the response
        u32 tries = 0;
        while (true) {
          tries += 1;
          XTSC_INFO(m_text, p_response_info->m_response << " Port #" << port_num << " Try #" << tries);
          xtsc_log_memory_response_event(m_binary, INFO_LOG_LEVEL, false, port_num, m_log_data_binary, p_response_info->m_response);
          if ((*m_respond_ports[port_num])->nb_respond(p_response_info->m_response)) {
            break;
          }
          wait(m_response_repeat);
        }
        m_last_response_time_stamp = sc_time_stamp();
        delete_response_info(p_response_info);
      }
    }

  }
  catch (const exception& error) {
    ostringstream oss;
    oss << "std::exception caught in response_thread of " << kind() << " '" << name() << "'." << endl;
    oss << "what(): " << error.what() << endl;
    xtsc_log_multiline(m_text, log4xtensa::FATAL_LOG_LEVEL, oss.str(), 2);
    throw;
  }

}



void xtsc_component::xtsc_arbiter::response_pwc_thread(void) {

  try {

    while (true) {
      wait(m_response_thread_event);
      XTSC_DEBUG(m_text, "response_pwc_thread woke up.");
      while (m_response_fifo.num_available()) {
        response_info *p_response_info;
        m_response_fifo.nb_read(p_response_info);
        u32             port_num          = get_port_from_response(p_response_info->m_response);
        req_rsp_info   *p_req_rsp_info    = NULL;
        u32             master_byte_width = m_master_byte_widths[port_num];
        bool            fini              = true;

        if (master_byte_width == m_slave_byte_width) {
          m_responses[0] = p_response_info;
          fini = (p_response_info->m_response.get_last_transfer() == true);
        }
        else {
          fini = convert_response(p_response_info, master_byte_width, p_req_rsp_info);
          delete_response_info(p_response_info);
        }

        for (u32 i=0; (m_responses[i] != NULL) && (i<4); ++i) {

          // Calculate delay (net => No Earlier Than time)
          sc_time receipt_net       = m_responses[i]->m_time_stamp + m_response_delay;
          sc_time last_response_net = m_last_response_time_stamp + (m_delay_from_receipt ? m_recovery_time : m_response_delay);
          sc_time latest_net        = (receipt_net > last_response_net) ? receipt_net : last_response_net;
          sc_time now               = sc_time_stamp();
          sc_time delay = (latest_net <= now) ? SC_ZERO_TIME : (latest_net - now);
          XTSC_DEBUG(m_text, "response_pwc_thread() doing wait for " << delay);
          wait(delay);
          // Forward the response
          u32 tries = 0;
          while (true) {
            tries += 1;
            XTSC_INFO(m_text, m_responses[i]->m_response << " Port #" << port_num << " Try #" << tries);
            xtsc_log_memory_response_event(m_binary, INFO_LOG_LEVEL, false, port_num, m_log_data_binary, m_responses[i]->m_response);
            if ((*m_respond_ports[port_num])->nb_respond(m_responses[i]->m_response)) {
              break;
            }
            wait(m_response_repeat);
          }
          m_last_response_time_stamp = sc_time_stamp();
          delete_response_info(m_responses[i]);
        }
        if (p_req_rsp_info && fini) {
          m_req_rsp_table[p_req_rsp_info->m_slot] = NULL;
          delete_req_rsp_info(p_req_rsp_info);
        }
      }
    }

  }
  catch (const exception& error) {
    ostringstream oss;
    oss << "std::exception caught in response_pwc_thread of " << kind() << " '" << name() << "'." << endl;
    oss << "what(): " << error.what() << endl;
    xtsc_log_multiline(m_text, log4xtensa::FATAL_LOG_LEVEL, oss.str(), 2);
    throw;
  }

}



bool xtsc_component::xtsc_arbiter::convert_response(response_info*&     p_response_info,
                                                    u32                 master_byte_width,
                                                    req_rsp_info*&      p_req_rsp_info)
{
  u8 id = p_response_info->m_response.get_id();
  if ((id >= m_num_slots) || (m_req_rsp_table[id] == NULL)) {
    ostringstream oss;
    oss << "Received response with " << ((id >= m_num_slots) ? "invalid" : "inactive") << " transaction id=" << (u32) id << ": "
        << p_response_info->m_response;
    throw xtsc_exception(oss.str());
  }
  if ((m_active_block_read_id != m_num_slots) && (m_active_block_read_id != id)) {
    ostringstream oss;
    oss << "While BLOCK_READ responses (tag=" << m_req_rsp_table[m_active_block_read_id]->m_p_first_request_info->m_request.get_tag()
        << ") are in progress, received unexpected response: " << p_response_info->m_response;
    throw xtsc_exception(oss.str());
  }
  p_req_rsp_info = m_req_rsp_table[id];
  bool last_transfer = p_response_info->m_response.get_last_transfer();
  bool fini = false;
  if (last_transfer) {
    p_req_rsp_info->m_num_last_xfer_rsp_received += 1;
    fini = (p_req_rsp_info->m_num_last_xfer_rsp_received == p_req_rsp_info->m_num_last_xfer_rsp_expected);
  }

  response_info *p_rsp_info = p_req_rsp_info->m_p_nascent_response ?
                              p_req_rsp_info->m_p_nascent_response :
                              new_response_info(p_req_rsp_info->m_p_first_request_info->m_request);

  if (!fini) {
    p_req_rsp_info->m_p_nascent_response = p_rsp_info;
  }

  /*
   * Handle single-response error responses
   *   RSP_ADDRESS_ERROR           single response
   *   RSP_ADDRESS_DATA_ERROR:     single response
   *   RSP_DATA_ERROR              normal number of responses
   */
  xtsc_response::status_t status = p_response_info->m_response.get_status();
  if (p_req_rsp_info->m_single_rsp_error_received ||
      ((status != xtsc_response::RSP_OK) && (status != xtsc_response::RSP_DATA_ERROR)))
  {
    if (p_req_rsp_info->m_single_rsp_error_received ||
        ((status == xtsc_response::RSP_ADDRESS_ERROR) || (status == xtsc_response::RSP_ADDRESS_DATA_ERROR)))
    {
      if (p_req_rsp_info->m_responses_sent) {
        ostringstream oss;
        oss << "Received address error response after some responses have already been sent upstream: " << p_response_info->m_response;
        throw xtsc_exception(oss.str());
      }
      if (!p_req_rsp_info->m_single_rsp_error_received) {
        p_req_rsp_info->m_single_rsp_error_received = true;
        p_rsp_info->m_response.set_status(status);
        p_rsp_info->m_response.set_last_transfer(true);
      }
      if (fini) {
        m_responses[0] = p_rsp_info;
        m_responses[0]->m_time_stamp = p_response_info->m_time_stamp;
      }
    }
    else {
      ostringstream oss;
      oss << "Received response with unsupported status: " << p_response_info->m_response;
      throw xtsc_exception(oss.str());
    }
  }
  else {
    if ((status == xtsc_response::RSP_DATA_ERROR) && (p_rsp_info->m_response.get_status() == xtsc_response::RSP_OK)) {
      p_rsp_info->m_response.set_status(xtsc_response::RSP_DATA_ERROR);
    }
    xtsc_request::type_t type = p_req_rsp_info->m_p_first_request_info->m_request.get_type();
    if ((type == xtsc_request::WRITE) || (type == xtsc_request::BLOCK_WRITE) || (type == xtsc_request::RCW)) {
      if (type == xtsc_request::RCW) {
        p_rsp_info->m_response.set_buffer(p_response_info->m_response.get_buffer());
      }
      if (fini) {
        m_responses[0] = p_rsp_info;
        m_responses[0]->m_time_stamp = p_response_info->m_time_stamp;
      }
    }
    else if ((type == xtsc_request::READ) || (type == xtsc_request::BLOCK_READ)) {
      const u8 *p_src = p_response_info->m_response.get_buffer();
      u32       size  = p_response_info->m_response.get_byte_size();
      if (master_byte_width > m_slave_byte_width) {
        // Master is wider than slave
        u8 *p_dst = p_rsp_info->m_response.get_buffer();
        u32 offset = (p_req_rsp_info->m_num_rsp_received * m_slave_byte_width) % master_byte_width;
        memcpy(p_dst+offset, p_src, size);
        if (fini || ((offset + size) == master_byte_width)) {
          m_responses[0] = p_rsp_info;
          m_responses[0]->m_response.set_last_transfer(fini);
          m_responses[0]->m_time_stamp = p_response_info->m_time_stamp;
        }
      }
      else {
        // Slave is wider than master
        p_rsp_info->m_response.set_buffer(p_src);
        m_responses[0] = p_rsp_info;
        if (type == xtsc_request::BLOCK_READ) {
          m_responses[0]->m_response.set_last_transfer(false);
          u32 reps = min(m_slave_byte_width, size) / master_byte_width;
          for (u32 i=1; i < reps; ++i) {
            m_responses[i] = new_response_info(p_rsp_info->m_response);
            m_responses[i]->m_response.set_buffer(p_src + master_byte_width*i);
            m_responses[i]->m_response.set_last_transfer(false);
          }
          if (fini) {
            m_responses[reps-1]->m_response.set_last_transfer(true);
          }
        }
      }
      if (type == xtsc_request::BLOCK_READ) {
        m_active_block_read_id = fini ? m_num_slots : id;
      }
    }
    else {
      ostringstream oss;
      oss << "Program Bug: " << xtsc_request::get_type_name(type) << " is not supported at line " << __LINE__ << " of " << __FILE__;
      throw xtsc_exception(oss.str());
    }
  }

  p_req_rsp_info->m_num_rsp_received += 1;
  if (m_responses[0] != NULL) {
    p_req_rsp_info->m_responses_sent     = true;
    p_req_rsp_info->m_p_nascent_response = NULL;
  }
  return fini;
}



u32 xtsc_component::xtsc_arbiter::get_port_from_response(const xtsc_response& response) {
  u32 route_id = response.get_route_id();
  u32 port_num = ((route_id & m_route_id_bits_mask) >> m_route_id_bits_shift);
  XTSC_DEBUG(m_text, response << " route_id=0x" << setfill('0') << hex << setw(8) << route_id << " => Port #" << dec << port_num);
  return port_num;
}



void xtsc_component::xtsc_arbiter::add_route_id_bits(xtsc_request& request, u32 port_num) {
  u32 route_id = request.get_route_id();
  route_id |= ((port_num << m_route_id_bits_shift) & m_route_id_bits_mask);
  request.set_route_id(route_id);
  XTSC_DEBUG(m_text, request << " route_id=0x" << setfill('0') << hex << setw(8) << route_id);
}



xtsc_component::xtsc_arbiter::request_info *xtsc_component::xtsc_arbiter::new_request_info(u32 port_num, const xtsc_request& request) {
  if (m_request_pool.empty()) {
    request_info *p_request_info = new request_info(request);
    XTSC_DEBUG(m_text, "Creating a new request_info " << p_request_info << " for " << request);
    p_request_info->m_request.set_byte_address(translate(port_num, p_request_info->m_request.get_byte_address()));
    return p_request_info;
  }
  else {
    request_info *p_request_info = m_request_pool.back();
    XTSC_DEBUG(m_text, "Reusing request_info " << p_request_info << " for " << request);
    m_request_pool.pop_back();
    p_request_info->m_request = request;
    p_request_info->m_request.set_byte_address(translate(port_num, p_request_info->m_request.get_byte_address()));
    p_request_info->m_time_stamp = sc_time_stamp();
    return p_request_info;
  }
}



xtsc_component::xtsc_arbiter::request_info *xtsc_component::xtsc_arbiter::new_request_info(const request_info& info) {
  if (m_request_pool.empty()) {
    request_info *p_request_info = new request_info(info);
    XTSC_DEBUG(m_text, "Creating a new request_info " << p_request_info << " for " << info.m_request);
    return p_request_info;
  }
  else {
    request_info *p_request_info = m_request_pool.back();
    XTSC_DEBUG(m_text, "Reusing request_info " << p_request_info << " for " << info.m_request);
    m_request_pool.pop_back();
    *p_request_info = info;
    return p_request_info;
  }
}



void xtsc_component::xtsc_arbiter::delete_request_info(request_info*& p_request_info) {
  XTSC_DEBUG(m_text, "Recycling request_info " << p_request_info);
  m_request_pool.push_back(p_request_info);
  p_request_info = 0;
}



xtsc_component::xtsc_arbiter::response_info *xtsc_component::xtsc_arbiter::new_response_info(const xtsc_response& response) {
  if (m_response_pool.empty()) {
    response_info *p_response_info = new response_info(response);
    XTSC_DEBUG(m_text, "Creating a new response_info " << p_response_info << " for " << response);
    return p_response_info;
  }
  else {
    response_info *p_response_info = m_response_pool.back();
    XTSC_DEBUG(m_text, "Reusing response_info " << p_response_info << " for " << response);
    m_response_pool.pop_back();
    p_response_info->m_response = response;
    p_response_info->m_time_stamp = sc_time_stamp();
    return p_response_info;
  }
}



xtsc_component::xtsc_arbiter::response_info *xtsc_component::xtsc_arbiter::new_response_info(const xtsc_request& request) {
  if (m_response_pool.empty()) {
    response_info *p_response_info = new response_info(request);
    XTSC_DEBUG(m_text, "Creating a new response_info " << p_response_info << " for " << request);
    return p_response_info;
  }
  else {
    response_info *p_response_info = m_response_pool.back();
    XTSC_DEBUG(m_text, "Reusing response_info " << p_response_info << " for " << request);
    m_response_pool.pop_back();
    p_response_info->m_response = request;
    p_response_info->m_time_stamp = sc_time_stamp();
    return p_response_info;
  }
}



void xtsc_component::xtsc_arbiter::delete_response_info(response_info*& p_response_info) {
  XTSC_DEBUG(m_text, "Recycling response_info " << p_response_info);
  m_response_pool.push_back(p_response_info);
  p_response_info = 0;
}



xtsc_address xtsc_component::xtsc_arbiter::translate(u32 port_num, xtsc_address address8) {
  if (!m_do_translation) return address8;
  assert(port_num < m_num_masters);
  xtsc_address new_address8 = address8;
  vector<xtsc_address_range_entry*> *p_translation_table = m_translation_tables[port_num];
  vector<xtsc_address_range_entry*>::iterator itt = p_translation_table->begin();
  for (; itt != p_translation_table->end(); ++itt) {
    if ((*itt)->m_start_address8 > address8) break;
    if (((*itt)->m_start_address8 <= address8) && ((*itt)->m_end_address8 >= address8)) {
      new_address8 += (*itt)->m_delta;
      break;
    }
  }
  XTSC_DEBUG(m_text, "translate(" << port_num << ", 0x" << hex << address8 << ") = 0x" << new_address8);
  return new_address8;
}



void xtsc_component::xtsc_arbiter::xtsc_request_if_impl::nb_request(const xtsc_request& request) {
  XTSC_DEBUG(m_arbiter.m_text, "nb_request fifo on port #" << m_port_num << " has " <<
                               m_arbiter.m_request_fifos[m_port_num]->num_free() << " free.");
  XTSC_VERBOSE(m_arbiter.m_text, request << " Port # " << m_port_num);
  xtsc_log_memory_request_event(m_arbiter.m_binary, VERBOSE_LOG_LEVEL, true, m_port_num, m_arbiter.m_log_data_binary, request);
  if (m_arbiter.m_read_only) {
    xtsc_request::type_t type = request.get_type();
    if ((type == xtsc_request::WRITE)       ||
        (type == xtsc_request::BLOCK_WRITE) ||
        (type == xtsc_request::BURST_WRITE) ||
        (type == xtsc_request::RCW))
    {
      ostringstream oss;
      oss << "read_only xtsc_arbiter '" << m_arbiter.name() << "' received request: " << request; 
      throw xtsc_exception(oss.str());
    }
  }
  if (m_arbiter.m_write_only) {
    xtsc_request::type_t type = request.get_type();
    if ((type == xtsc_request::READ)       ||
        (type == xtsc_request::BLOCK_READ) ||
        (type == xtsc_request::BURST_READ) ||
        (type == xtsc_request::RCW))
    {
      ostringstream oss;
      oss << "write_only xtsc_arbiter '" << m_arbiter.name() << "' received request: " << request; 
      throw xtsc_exception(oss.str());
    }
  }
  if (m_arbiter.m_immediate_timing) { 
    m_arbiter.do_request_immediate_timing(m_port_num, request);
  }
  else {
    m_arbiter.do_request(m_port_num, request);
  }
}



void xtsc_component::xtsc_arbiter::do_request_immediate_timing(u32 port_num, const xtsc_request& request) {
  // Check for lock on a different port
  if (m_lock && (port_num != m_token)) {
    xtsc_response response(request, xtsc_response::RSP_NACC);
    XTSC_VERBOSE(m_text, response << " Port #" << port_num << " (Arbiter locked to port #" << m_token << ")");
    xtsc_log_memory_response_event(m_binary, VERBOSE_LOG_LEVEL, false, port_num, false, response);
    (*m_respond_ports[port_num])->nb_respond(response);
    return;
  }
  // Create our copy of the request
  request_info *p_request_info = new_request_info(port_num, request);
  // Accept this one as our current request
  m_token = port_num;
  m_lock = !p_request_info->m_request.get_last_transfer();
  handle_request(p_request_info, port_num);
}



void xtsc_component::xtsc_arbiter::do_request(u32 port_num, const xtsc_request& request) {
  // Check if we've got room for this request
  if (!m_request_fifos[port_num]->num_free()) {
    xtsc_response response(request, xtsc_response::RSP_NACC);
    XTSC_VERBOSE(m_text, response << " Port #" << port_num << " (Request fifo full)");
    xtsc_log_memory_response_event(m_binary, VERBOSE_LOG_LEVEL, false, port_num, false, response);
    (*m_respond_ports[port_num])->nb_respond(response);
    return;
  }
  // Create our copy of the request
  request_info *p_request_info = new_request_info(port_num, request);
  // Add to request fifo
  XTSC_DEBUG(m_text, request << " Port #" << port_num << " (nb_request: Added to request fifo)");
  m_request_deques[port_num]->push_back(p_request_info);
  m_request_fifos[port_num]->nb_write(0);
  m_arbiter_thread_event.notify(SC_ZERO_TIME);
}



xtsc_component::xtsc_arbiter::req_rsp_info *xtsc_component::xtsc_arbiter::new_req_rsp_info(request_info *p_first_request_info) {
  req_rsp_info *p_req_rsp_info;
  if (m_req_rsp_info_pool.empty()) {
    p_req_rsp_info = new req_rsp_info();
    XTSC_DEBUG(m_text, "Creating a new req_rsp_info " << p_req_rsp_info);
  }
  else {
    p_req_rsp_info = m_req_rsp_info_pool.back();
    XTSC_DEBUG(m_text, "Reusing req_rsp_info " << p_req_rsp_info);
    m_req_rsp_info_pool.pop_back();
  }
  p_req_rsp_info->m_p_first_request_info = p_first_request_info;
  return p_req_rsp_info;
}



void xtsc_component::xtsc_arbiter::delete_req_rsp_info(req_rsp_info*& p_req_rsp_info) {
  XTSC_DEBUG(m_text, "Recycling req_rsp_info " << p_req_rsp_info);
  delete_request_info(p_req_rsp_info->m_p_first_request_info);
  memset(p_req_rsp_info, 0, sizeof(req_rsp_info));
  m_req_rsp_info_pool.push_back(p_req_rsp_info);
  p_req_rsp_info = 0;
}



void xtsc_component::xtsc_arbiter::xtsc_request_if_impl::nb_peek(xtsc_address address8, u32 size8, u8 *buffer) {
  m_arbiter.m_request_port->nb_peek(m_arbiter.translate(m_port_num, address8), size8, buffer);
}



void xtsc_component::xtsc_arbiter::xtsc_request_if_impl::nb_poke(xtsc_address address8, u32 size8, const u8 *buffer) {
  m_arbiter.m_request_port->nb_poke(m_arbiter.translate(m_port_num, address8), size8, buffer);
}



bool xtsc_component::xtsc_arbiter::xtsc_request_if_impl::nb_peek_coherent(xtsc_address  virtual_address8,
                                                                          xtsc_address  physical_address8,
                                                                          u32           size8,
                                                                          u8           *buffer)
{
  xtsc_address address8 = m_arbiter.translate(m_port_num, physical_address8);
  return m_arbiter.m_request_port->nb_peek_coherent(virtual_address8, address8, size8, buffer);
}



bool xtsc_component::xtsc_arbiter::xtsc_request_if_impl::nb_poke_coherent(xtsc_address  virtual_address8,
                                                                          xtsc_address  physical_address8,
                                                                          u32           size8,
                                                                          const u8     *buffer)
{
  xtsc_address address8 = m_arbiter.translate(m_port_num, physical_address8);
  return m_arbiter.m_request_port->nb_poke_coherent(virtual_address8, address8, size8, buffer);
}



bool xtsc_component::xtsc_arbiter::xtsc_request_if_impl::nb_fast_access(xtsc_fast_access_request &request) {
  xtsc_address orig_address8 = request.get_translated_request_address();
  xtsc_address address8 = m_arbiter.translate(m_port_num, orig_address8);
  request.translate_request_address(address8);

  if (!m_arbiter.m_request_port->nb_fast_access(request)) {
    return false;
  }

  /* remove anything mapped before this address hits. When the address
     hits, remove anything outside of its range */
  if (m_arbiter.m_do_translation) {
    const vector<xtsc_address_range_entry*> *p_translation_table 
      = m_arbiter.m_translation_tables[m_port_num];
    for (unsigned i = 0; i < p_translation_table->size(); ++i) {
      xtsc_address end_address8 = (*p_translation_table)[i]->m_end_address8;
      xtsc_address start_address8 = (*p_translation_table)[i]->m_start_address8;
      if (orig_address8 >= start_address8 && orig_address8 <= end_address8) {
        xtsc_fast_access_block min_block(orig_address8, start_address8, end_address8);
        if (!request.restrict_to_block(min_block)) {
          return false;
        }
        break;
      }
      if (!request.remove_address_range(orig_address8, start_address8, end_address8)) {
        return false;
      }
    }
  }
  
  return true;
}



void xtsc_component::xtsc_arbiter::xtsc_request_if_impl::nb_load_retired(xtsc_address address8) {
  address8 = m_arbiter.translate(m_port_num, address8);
  m_arbiter.m_request_port->nb_load_retired(address8);
}



void xtsc_component::xtsc_arbiter::xtsc_request_if_impl::nb_retire_flush() {
  m_arbiter.m_request_port->nb_retire_flush();
}



void xtsc_component::xtsc_arbiter::xtsc_request_if_impl::nb_lock(bool lock) {
  XTSC_INFO(m_arbiter.m_text, "nb_lock(" << boolalpha << lock << ") called on Port #" << m_port_num);
  if (m_arbiter.m_dram_lock) {
    m_arbiter.m_dram_locks[m_port_num] = lock;
    if (!lock && (m_port_num == m_arbiter.m_token)) {
      m_arbiter.m_lock = false;
    }
  }
  else {
    m_arbiter.m_request_port->nb_lock(lock);
  }
}



void xtsc_component::xtsc_arbiter::xtsc_request_if_impl::register_port(sc_port_base& port, const char *if_typename) {
  if (m_p_port) {
    ostringstream oss;
    oss << "Illegal multiple binding detected to xtsc_arbiter '" << m_arbiter.name() << "' m_request_exports[" << m_port_num
        << "]: " << endl;
    oss << "  " << port.name() << endl;
    oss << "  " << m_p_port->name();
    throw xtsc_exception(oss.str());
  }
  XTSC_INFO(m_arbiter.m_text, "Binding '" << port.name() << "' to xtsc_arbiter::m_request_exports[" << m_port_num << "]");
  m_p_port = &port;
}



bool xtsc_component::xtsc_arbiter::xtsc_respond_if_impl::nb_respond(const xtsc_response& response) {
  XTSC_VERBOSE(m_arbiter.m_text, response);
  xtsc_log_memory_response_event(m_arbiter.m_binary, VERBOSE_LOG_LEVEL, true, 0, m_arbiter.m_log_data_binary, response);
  if (m_arbiter.m_immediate_timing) {
    u32 port_num = m_arbiter.get_port_from_response(response);
    return (*m_arbiter.m_respond_ports[port_num])->nb_respond(response);
  }
  else {
    if (response.get_status() == xtsc_response::RSP_NACC) {
      if (m_arbiter.m_waiting_for_nacc) {
        m_arbiter.m_request_got_nacc = true;
        return true;
      }
      else {
        ostringstream oss;
        oss << "xtsc_arbiter '" << m_arbiter.name() << "' received nacc too late: " << response << endl;
        oss << " - Possibly something is wrong with the downstream device" << endl;
        oss << " - Possibly this arbiter's \"nacc_wait_time\" needs to be adjusted";
        throw xtsc_exception(oss.str());
      }
    }
    if (!m_arbiter.m_response_fifo.num_free()) {
      XTSC_VERBOSE(m_arbiter.m_text, response << " (Rejected: Response fifo full)");
      return false;
    }
    response_info *p_response_info = m_arbiter.new_response_info(response);
    m_arbiter.m_response_fifo.nb_write(p_response_info);
    m_arbiter.m_response_thread_event.notify(SC_ZERO_TIME);
    return true;
  }
}



void xtsc_component::xtsc_arbiter::xtsc_respond_if_impl::register_port(sc_port_base& port, const char *if_typename) {
  if (m_p_port) {
    ostringstream oss;
    oss << "Illegal multiple binding detected to xtsc_arbiter '" << m_arbiter.name() << "' m_respond_export: " << endl;
    oss << "  " << port.name() << endl;
    oss << "  " << m_p_port->name();
    throw xtsc_exception(oss.str());
  }
  XTSC_INFO(m_arbiter.m_text, "Binding '" << port.name() << "' to xtsc_arbiter::m_respond_export");
  m_p_port = &port;
}



